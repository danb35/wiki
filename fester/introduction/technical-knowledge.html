<!--
title: 1.4 What technical knowledge do you need? 
description: Just how much does TrueNAS help you avoid needing technical knowledge?
published: true
date: 2025-04-02T20:38:15.485Z
tags: 
editor: ckeditor
dateCreated: 2025-04-02T16:42:55.931Z
-->

<p>Implementing TrueNAS definitely reduces the amount of technical knowledge you will need, but it doesn't eliminate it completely.</p>
<ul>
  <li>TrueNAS is a carefully pre-packaged version of Linux &amp; ZFS etc., avoiding the need for you to install each component yourself and then make them all work together, and avoid the huge mass of technical knowledge that this would require.</li>
  <li>TrueNAS comes with a pretty comprehensive UI, allowing you to do almost all of the set-up and day to day management of your NAS through the UI, without having to know the command line methods of configuring everything that you would otherwise need.</li>
</ul>
<p>However, this does <i><strong><u>NOT</u></strong></i> mean that you can design, install, set-up, manage on a day-to-day basis, and deal with any issues without any technical understanding, though you will certainly need less knowledge that you might otherwise do.</p>
<p>HexOS is purported to reduce the level of knowledge you need to setup and manage a TrueNAS installation, however the Addams family share a concern that if things go wrong you will then have even less technical knowledge and experience to draw upon to help fix things.</p>
<h2>So, what do you need to learn?</h2>
<p>This is a fairly opinionated list (and contributors should feel free to modify this list according to their own views):</p>
<ul>
  <li>Basic understanding of ZFS:<ul>
      <li>Pools, datasets and zVolumes</li>
      <li>vDevs</li>
      <li>Mirrors vs. RAIDZ1/2/3</li>
      <li>Scrubs</li>
      <li>Snapshots (and Checkpoints)</li>
      <li>Asynchronous vs. synchronous writes</li>
      <li>When to use - or more often <strong>not to use</strong> - the various specialised performance enhancement “vDevs” that ZFS has</li>
      <li>What you should and shouldn't do (for fear of making things worse) if things do go wrong</li>
      <li>Resilvering</li>
      <li>RAIDZ expansion</li>
      <li>Replication</li>
    </ul>
  </li>
  <li>Basic understanding of SMART disk diagnostics</li>
  <li>Basic understanding of TCP/IP networking:<ul>
      <li>Initial setup</li>
      <li>For networking to containerised / virtualised applications</li>
    </ul>
  </li>
  <li>Basic IT management concepts:<ul>
      <li>How safe is your data with ZFS?</li>
      <li>What constitutes a backup? Redundancy, snapshots, checkpoints, ZFS replication</li>
    </ul>
  </li>
</ul>
<h2>Basic ZFS Concepts</h2>
<h3>Pools, Datasets and zVolumes</h3>
<ul>
  <li>Pools: The basic unit of ZFS storage. When you install TrueNAS you get a <code>boot-pool</code>which contains TrueNAS and which you should <strong>not</strong> write files to yourself. To store your files, apps and virtualised operating systems you will need one or more storage pools you create - each pool is a self-contained storage group.</li>
  <li>Datasets: Each pool has a root dataset with the same name as the pool - and these are normally mounted as subpaths of <code>/mnt</code>. Datasets can contain other datasets, zVolumes or normal directories and files. From a Linux perspective, each dataset is separately mounted - so copying or moving data between datasets will involve a physical copy of the files.</li>
  <li>zVolumes are emulated block devices or virtual disks used for virtualisation or iSCSI access. TrueNAS has no knowledge of what is stored inside, and so <strong>cannot</strong> e.g. predict what data will be needed next and pre-fetch it. Moreover, whilst ZFS can protect the integrity of the overall pool against e.g. sudden power loss, without knowledge of how the zVolume is used, it cannot do anything to help preserve the integrity of the virtualised file system it contains - and this means that you need to tell ZFS to commit each and every write to disk immediately (so called synchronous writes) and this can have a very significant performance impact on HDD writes. So if you are going to use virtualisation and zVolumes, you need to design the storage for these differently than from the storage for normal files (much more on this later).</li>
</ul>
<h3>vDevs</h3>
<p>A pool is made up of one or more virtual-devices or vDevs.</p>
<p>A vDev is formed from one or more physical disks (HDDs, SSDs, NVMe etc.) or disk partitions - and (in almost all circumstances) these should typically all be the same type and size of disk.</p>
<p>The primary type of vDev is the <i>Data vDev</i> - and every pool must have at least one of these.&nbsp;</p>
<p>There are various secondary types of vDev - SLOG, L2ARC, Dedup, Special Allocation - each of which is designed to solve a specific performance issue which occur with specific use cases (more on these later in this wiki). When designing your pools, you should assume that you <i><strong>do not</strong></i> need any of these unless you have a specific use case which will need them - do <i><strong>not</strong></i> just add these to your design because you think that they must be useful, because if you don't have a use case they will at best cost you money to do absolutely nothing or at worse have a negative impact on performance rather than a positive one.</p>
<p>You can also have spare drives which are unused, ready to be switched in to replace drives which fail - these are not vDevs but they are configured in a similar way.</p>
<p>Data, Slog, Dedup and Special Allocation vDevs are critical to the operation of the pool, and if you lose complete access to any one of these vDevs, your pool (and all the data in it) are most likely going to be gone forever (which is why you still need backups). The more vDevs you have, the more links in the chain that can experience problems - and thus the greater the need for each of the vDevs to have some redundancy in order to survive individual hardware issues. With the exception of single drive, single vDev pools, unless you really know what you are doing and you are prepared to accept fully&nbsp;the risks associated, you should always plan for redundant vDevs, and you should NOT under any circumstances stripe data across multiple single drive vDevs. (L2ARC Cache vDevs can be single drive as they can be lost without any impact to the data integrity of the pool.)</p>
<h3>Mirrors vs. RAIDZ</h3>
<p>There are two basic ways to make a vDev redundant: Mirrors and RAIDZ:</p>
<ul>
  <li>Mirrors: 2 or more identical copies of an entire disk. You can add or remove drives from a mirror at will. (From a technical perspective for adding and removing mirrors, a single drive vDev is considered a non-redundant mirror. For pools that are all mirror vDevs, you can also remove entire vDevs at a later date.) &nbsp;</li>
  <li>RAIDZ: a RAIDZ vDev consists of 2 or more data disks, and 1-3 parity disks (a simplified explanation useful for conceptual understanding and for planning - in actual use data is not physically stored stored in this way). In recent versions of TrueNAS SCALE you can add drives to an existing RAIDZ vDev through “RAIDZ Expansion” - however you <strong>cannot remove drives</strong> from a RAIDZ vDev. Furthermore, once you have chosen the parity level and formed your pool, you cannot later increase or decrease it - so plan carefully, think ahead if you ever plan to expand your RAIDZ vDev, and if in doubt go for two or more parity drives. A simple rule of thumb is to have 2 or more parity drives if you have a 4 or more data drives in the vDev or if you have 3 or more data drives of 8TB or greater.&nbsp;</li>
</ul>
<p><strong>Important:</strong> Redundancy provides more safety than simply recovering from the entire loss of a drive. In ZFS, each record has a checksum associated with it, and when ZFS detects a corrupted block because the checksum doesn't match, the redundant copies can be used to recover the record or file that is corrupted. This is another reason <strong>not</strong> to use non-redundant vDevs.</p>
<h3>Scrubs</h3>
<p>A ZFS scrub reads every block of data in a pool, and checks that the data matches the checksum. If not, ZFS attempts to correct the data using the vDev redundancy.</p>
<p>You should run a scrub every 1-3 months at a minimum.</p>
<h3>Snapshots (and Checkpoints)</h3>
<p>A <i>Snapshot</i> is a way of freezing the contents of a dataset or zVolume so that you can go back to the contents at a later date. For datasets you can go back and find any individual file that may have been changed; for zVolumes you can only roll-back the entire zVolume.</p>
<p>A <i>Checkpoint</i> is a specialised type of Snapshot that allows for greater recovery if there are integrity problems with the pool. It is not intended to be used as a replacement for regular Snapshots, but can be a useful tool for boot-pool during upgrades or for other pools when you are undertaking a major change.</p>
<h3>Replication</h3>
<p>ZFS <i>Replication</i> is a way of copying a snapshot from a dataset in one pool to a different pool on the same or different server.&nbsp;</p>
<p>The key point about ZFS Replication is that it is incremental and therefore extremely efficient - ZFS knows what snapshot is at the destination dataset, and can match it to the same snapshot at the source and then only send any changes that have happened since.</p>
<h3>Asynchronous vs. synchronous writes</h3>
<p>Normal <i>Asynchronous</i> writes are queued up for (normally) 5 seconds before being written to disk as a Transaction Group (TXG) with full pool integrity (i.e. either all writes succeed or all writes fail).&nbsp;</p>
<p>However whilst this maintains the integrity of the ZFS pool, it does not guarantee the integrity of the internal structure of virtual disks nor does it guarantee that business-critical database transactions have been written to disk.</p>
<p>If you need these integrities to be guaranteed as well, then you need to turn on synchronous writes. For these, in addition to queuing the writes for 5 seconds as above, it immediately writes a second copy of the data to the Zero Intent Log (ZIL) which can be used when TrueNAS starts to catch up on any delayed writes that might otherwise be lost, thus maintaining both virtual disk and database integrity.&nbsp;</p>
<p>Unfortunately using synchronous writes has a very detrimental impact on performance, especially if you are writing the ZIL to HDD, and so you should either place the data itself on SSD (so that the ZIL is there also) or implement a special (mirrored) SLOG vDev to divert the ZIL writes from HDD to SSD. (Note: The Linux <code>fsync</code> issued at the end of writing a file to flush data to disk also creates a ZIL write even for normal asynchronous writes, however unless you are frequently writing small sequential files the performance impact of this is usually limited.)&nbsp;</p>
<h3>Specialised performance enhancement vDev types</h3>
<p>The following vDev types are specialised secondary vDevs that can be used to address specific performance issues with specific use cases:</p>
<ul>
  <li>SLOG - as described above diverts ZIL writes from the data vDev to a separate device dedicated to ZIL writes - and to be effective this needs to be significantly faster technology than the data vDev - so SSD when data is on HDD, or NVMe / Optane when the data is on normal SSD.</li>
  <li>L2ARC - ZFS already caches data read from disk in normal memory (which is why you need to have more memory for ZFS systems than non-ZFS), and if you want to cache more data then the best solution is often to add more memory. However there are occasions where this is not possible or proves to be ineffective and for these situations a secondary cache L2ARC can be beneficial.</li>
  <li>Dedup - until Fangtooth introduces a rewritten Dedup algorithm and this has been proven to be bug free and effective, the easiest rule of thumb for Deduplication is simply “don't do it”!!! It is designed for <i><strong>VERY</strong></i> specific use cases, and needs significant additional hardware to be even half effective. If you have a genuine deduplication issue, then either wait for the rewritten version or use a deduplication script that uses Block Cloning instead.</li>
  <li>Special Allocation - of all the special types of vDev, this is perhaps the most useful and most used, but you do have to be careful about how you implement it. Because this vDev is essential to your pool, it must be a redundant vDev, usually mirrored, recommended to have the same redundancy as the data vDev i.e. a 3-way mirror for a RAIDZ2 data vDev. This will generally always be used to store the metadata blocks (which typically can make up 30%-50% of all reads - but which are of course preferentially cached in main memory ARC), but on a dataset-by-dataset basis you can also tell ZFS to use it for small files. Thus it can effectively create a 2-tier pool where metadata and small active files are stored on e.g. NVMe whilst large usually inactive files are stored on HDD</li>
</ul>
<h3>What to do if things do go wrong</h3>
<p>Even in the most correctly configured systems, occasionally things do go wrong and your pool either becomes degraded but stays online or ZFS takes it offline completely because the integrity has become suspect and in order to avoid any further corruption. ZFS expects your hardware to behave in a certain way, and if any part of your system is mis-configured, then these sorts of issues become more likely.</p>
<p>If your pool becomes degraded, and you are technically knowledgeable about ZFS, then many recovery actions can be undertaken safely through the UI.</p>
<p>However if your pool has gone offline or you are not 100% confident about how to recover it to fully working order, then your first action should be to seek help from experts on the TrueNAS forums - to put things bluntly, if you try to resolve issues when you are guessing about what to do, you could make the corruption worse and turn a potentially recoverable pool into a completely irrecoverable one where your data becomes permanently inaccessible. &nbsp;&nbsp;</p>
<h3>Resilvering</h3>
<p>Resilvering is the process of restoring full redundancy when your system has lost one or more drives and become partially or fully degraded (but is still online).&nbsp;</p>
<h3>RAIDZ expansion</h3>
<p>If you have a RAIDZ vDev, from ElectricEel onwards you can now add drives to the data part of the data vDev (retaining the same parity level) to increase your useable storage space.</p>
<h2>Basic understanding of SMART disk diagnostics</h2>
<p>SMART is a technology whereby each disk can tell the operating system about its internal operating status. TrueNAS can automatically run regular SMART tests on your system, and you are recommended to run SMART Short Tests at least weekly and SMART Long Tests at least monthly.</p>
<p>@JoeSchmuck's Multi-Report script can be used to check on the status of your SMART tests, Scrubs and SMART attributes and inform you if any of your disks are starting to experience early signs of failure.</p>
<h2>Basic understanding of TCP/IP networking</h2>
<h3>Initial setup</h3>
<p>To access your NAS from your LAN, you will need to configure the server's network cards correctly, and you will need to have a basic understanding of TCP/IP network addressing to achieve this. (Teaching this is not within the scope of this Wiki - however there are lots of resources on the Internet for this.)</p>
<h3>For networking to containerised / virtualised applications</h3>
<p>When you implement applications or containers or virtualised operating systems, these will typically also need network addresses and / or ports and a slightly greater understanding of TCP/IP networking will be needed to ensure that this is done correctly.</p>
<h2>Basic IT management concepts:</h2>
<h3>How safe is your data with ZFS?</h3>
<p>ZFS is designed to write data to pools in Transaction Groups (TXGs) in such a way that a TXG is either fully written to disk or effectively not written at all. Thus ZFS pools maintain integrity even after sudden power loss or O/S crash, and do not need e.g. a Windows <code>chkdsk</code> or Linux <code>fsck</code> to be run to restore integrity. However…</p>
<ul>
  <li>The integrity of underlying virtual file systems or database transactions is not guaranteed unless you do synchronous writes</li>
  <li>Despite integrity supposedly guaranteed, there are anecdotal examples of pools failing to load after a reboot, particularly when a resilver or RAIDZ expansion has been interrupted. That said, to put this in context, ZFS is still far safer for your data integrity than many other file systems - but it is NOT infallible. You should NOT rely on the pool retaining integrity to safeguard your irreplaceable data - make sure that you do backups and that you have checked that they are working.</li>
  <li>If you lose more disks than your redundancy level, you will lose your pool - and e.g. a disk controller issue (such as overheating) can cause this.</li>
  <li>The integrity only works if data is written to disk in the exact sequence specified by ZFS, and you must avoid at all costs disk controllers (especially hardware RAID controllers) that may resequence writes to reduce seek times.</li>
</ul>
<h3>What constitutes a backup? Redundancy, snapshots, checkpoints, ZFS replication</h3>
<p>The definition of a backup is one where you can recover your important and irreplaceable data regardless of what happens to your primary copy (e.g. a fire guts your entire home) - which means off-site. Anything else is only <i>at-best</i> a partial backup, if indeed it is a backup at all.</p>
<ul>
  <li>Snapshots - same pool, lose the pool you lose all snapshots</li>
  <li>Replication within the same server - have a Power Supply fire or a power supply surge and you may lose all the drives in your server at once</li>
  <li>Replication to a server elsewhere in your building - definitely getting close to a genuine backup - but a site-wide fire could cause both primary and backup servers to be lost</li>
  <li>Off-site replication to the cloud or to a buddy's server across town - this is a genuine backup.</li>
</ul>
<p>This is NOT to say that e.g. Snapshots don't have their benefits - they are very fast and low cost, and they can assist with recovering data that has been accidentally deleted or e.g. encrypted by ransomware, but whilst they may address some risks, they do not address many others.</p>
<p>&nbsp;</p>
<h6><span class="text-big">Links</span></h6>
<figure class="table">
  <table>
    <tbody>
      <tr>
        <td style="border-bottom:1px solid rgb(97, 97, 97);border-left:1px solid rgb(97, 97, 97);border-right:1px solid rgb(97, 97, 97);border-top:1px solid rgb(97, 97, 97);padding:0.5rem 0.75rem;width:510.016px;">Previous - <a href="/fester/introduction/which-truenas">1.3 Which version of TrueNAS?</a></td>
        <td style="background-color:rgb(23, 23, 23);border-bottom:1px solid rgb(97, 97, 97);border-left:1px solid rgb(97, 97, 97);border-right:1px solid rgb(97, 97, 97);border-top:1px solid rgb(97, 97, 97);padding:0.5rem 0.75rem;text-align:center;"><a href="https://wiki.familybrown.org/fester/index">Index</a></td>
        <td style="border-bottom:1px solid rgb(97, 97, 97);border-left:1px solid rgb(97, 97, 97);border-right:1px solid rgb(97, 97, 97);border-top:1px solid rgb(97, 97, 97);padding:0.5rem 0.75rem;text-align:right;width:508.375px;">Next - <a href="https://wiki.familybrown.org/e/en/fester/introduction/structure">1.5 The Structure of this Wiki</a></td>
      </tr>
    </tbody>
  </table>
</figure>
